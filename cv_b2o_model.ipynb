{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import nltk, re, time\n",
    "from langdetect import detect\n",
    "from contractions import get_contractions\n",
    "from sqlalchemy import create_engine\n",
    "from pprint import pprint\n",
    "from nltk.corpus import stopwords\n",
    "import chars2vec\n",
    "import sklearn.decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import string\n",
    "import re\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "import gensim\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.utils import class_weight\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU, GlobalMaxPool1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import optimizers\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.initializers import Constant\n",
    "\n",
    "# We download stopwords package\n",
    "# nltk.download('stopwords')\n",
    "contractions = get_contractions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "engine = create_engine('mysql://root:@localhost:3306/steam')\n",
    "# steam_data_query = \"\"\"SELECT url AS reviewid, content, CAST(recommend AS SIGNED) AS recommend\n",
    "#     FROM latest_review\"\"\"\n",
    "train_val_data_query = \"\"\"SELECT gameid, url, CAST(recommend AS SIGNED) AS recommend, hours_2w, hours_all, posttime, updatetime, EAG, compensation, content, initial_release_date, lang \n",
    "FROM latest_review \n",
    "WHERE url NOT IN (SELECT DISTINCT url FROM test_set) \n",
    "AND lang = 'en';\n",
    "\"\"\"\n",
    "\n",
    "test_data_query = \"\"\"SELECT gameid, url, CAST(recommend AS SIGNED) AS recommend, hours_2w, hours_all, posttime, updatetime, EAG, compensation, content, initial_release_date, lang\n",
    "FROM test_set;\"\"\"\n",
    "\n",
    "df_train_val = pd.read_sql(train_val_data_query, engine)\n",
    "df_test = pd.read_sql(test_data_query, engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(data):\n",
    "    review_lines = []\n",
    "\n",
    "    lines = data['content'].values.tolist()\n",
    "\n",
    "\n",
    "    for line in lines:\n",
    "        tokens = word_tokenize(line)\n",
    "        # convert to lower case\n",
    "        tokens = [w.lower() for w in tokens]\n",
    "\n",
    "        new_text = []\n",
    "        for word in tokens:\n",
    "            if word in contractions:\n",
    "                new_text.append(contractions[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "\n",
    "        text = \" \".join(new_text)\n",
    "        # remove punctuation from each word    \n",
    "    #     table = str.maketrans('', '', string.punctuation)\n",
    "    #     stripped = [w.translate(table) for w in tokens]\n",
    "        # remove remaining tokens that are not alphabetic\n",
    "    #     words = [word for word in stripped if word.isalpha()]\n",
    "\n",
    "        words = word_tokenize(text)\n",
    "        # filter out stop words    \n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        words = [w for w in words if not w in stop_words]\n",
    "        review_lines.append(words)\n",
    "        \n",
    "    return review_lines;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(review_lines))\n",
    "skf = StratifiedKFold(n_splits = 5, shuffle = True)\n",
    "num_folds = skf.get_n_splits(X)\n",
    "for index, (train_index, val_index) in enumerate(skf.split(X, y)):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
