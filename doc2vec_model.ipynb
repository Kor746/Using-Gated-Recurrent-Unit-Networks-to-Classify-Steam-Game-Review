{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import nltk, re, time\n",
    "from langdetect import detect\n",
    "from contractions import get_contractions\n",
    "from sqlalchemy import create_engine\n",
    "from pprint import pprint\n",
    "from nltk.corpus import stopwords\n",
    "import chars2vec\n",
    "import sklearn.decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import string\n",
    "import re\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "import gensim\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.utils import class_weight\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU, GlobalMaxPool1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import optimizers\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import tqdm\n",
    "from keras.initializers import Constant\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/admin/Documents/Queens_Masters_Courses/Deep_Learning/course_project/best/pre_processed_steam_reviews_final2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'game made lose hope played game open beta came na eu excited beacuse jake song former developer lineage game director game much fun pvp system update came resisted playing game quitted around came back end good erenor update came erenor update destroyed game even tho dead update came erenor update litterally destroyed might ask well grind new levels normal think player trying kill faction players players everyone quitted wait update included new armor believe needed obsidian ayanand gear costed reccomend garbageage play lineage prelude interlude private server try black desert online fan open world pvp'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['content'].values.tolist()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    subjectively compilation mediocre minigames gr...\n",
      "1    game made lose hope played game open beta came...\n",
      "2    extremely visually pleasing enticing story sol...\n",
      "3    battlefield sensations back game go back sourc...\n",
      "4    games reason steam requirement retail copy goo...\n",
      "Name: content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.head(5)['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['subjectively', 'compilation', 'mediocre', 'minigames', 'group', 'friends', 'play', 'avoid'], ['game', 'made', 'lose', 'hope', 'played', 'game', 'open', 'beta', 'came', 'na', 'eu', 'excited', 'beacuse', 'jake', 'song', 'former', 'developer', 'lineage', 'game', 'director', 'game', 'much', 'fun', 'pvp', 'system', 'update', 'came', 'resisted', 'playing', 'game', 'quitted', 'around', 'came', 'back', 'end', 'good', 'erenor', 'update', 'came', 'erenor', 'update', 'destroyed', 'game', 'even', 'tho', 'dead', 'update', 'came', 'erenor', 'update', 'litterally', 'destroyed', 'might', 'ask', 'well', 'grind', 'new', 'levels', 'normal', 'think', 'player', 'trying', 'kill', 'faction', 'players', 'players', 'everyone', 'quitted', 'wait', 'update', 'included', 'new', 'armor', 'believe', 'needed', 'obsidian', 'ayanand', 'gear', 'costed', 'reccomend', 'garbageage', 'play', 'lineage', 'prelude', 'interlude', 'private', 'server', 'try', 'black', 'desert', 'online', 'fan', 'open', 'world', 'pvp'], ['extremely', 'visually', 'pleasing', 'enticing', 'story', 'solid', 'good', 'fps'], ['battlefield', 'sensations', 'back', 'game', 'go', 'back', 'sources', 'essences', 'game', 'super', 'fun', 'play', 'realistic', 'beautiful', 'game', 'even', 'ue', 'engine', 'super', 'job', 'game', 'rocks'], ['games', 'reason', 'steam', 'requirement', 'retail', 'copy', 'good', 'game', 'fun', 'times', 'released', 'held', 'constant', 'spot', 'top', 'worldwide', 'players', 'infestation', 'amazing', 'online', 'great', 'times', 'great', 'memories']]\n"
     ]
    }
   ],
   "source": [
    "steam_reviews = [word_tokenize(word) for word in data['content'].values.tolist()]\n",
    "print(steam_reviews[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Doc2vec model\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(steam_reviews)]\n",
    "model = Doc2Vec(documents, vector_size = 300, negative = 5, min_count = 1, workers = 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('fucking', 0.9278612732887268),\n",
       " ('ass', 0.9196205139160156),\n",
       " ('fuck', 0.9130381941795349),\n",
       " ('trash', 0.8737033605575562),\n",
       " ('garbage', 0.8705238103866577),\n",
       " ('crap', 0.8675743937492371),\n",
       " ('sfucking', 0.8616911768913269),\n",
       " ('holy', 0.8486007452011108),\n",
       " ('conned', 0.8462146520614624),\n",
       " ('peice', 0.8435782194137573)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Doc2vec model\n",
    "vector = model.infer_vector([\"positive\", \"response\"])\n",
    "print(len(vector))\n",
    "model.wv.most_similar('shit', topn = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(rev_rows, rev_cols):\n",
    "    print(\"Building model...\")\n",
    "    model = Sequential()\n",
    "\n",
    "#     embedding_layer = Embedding(num_words,\n",
    "#                                EMBEDDING_DIM,\n",
    "#                                embeddings_initializer = Constant(embedding_matrix),\n",
    "#                                input_length = MAX_LENGTH,\n",
    "#                                trainable = False)\n",
    "\n",
    "#     model.add(embedding_layer)\n",
    "    model.add(Dense(128, activation = 'relu', input_shape=(rev_rows, rev_cols)))\n",
    "    # Currently 64, 0.4, 0.4\n",
    "    model.add(GRU(units = 128, dropout = 0.4, recurrent_dropout = 0.4))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "    adam = optimizers.Adam(lr = 0.0001)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "\n",
    "#     print('Summary of the built model...')\n",
    "    print(model.summary())\n",
    "    return model;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tok_content'] = data['content'].map(word_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['doc_vec'] = data['tok_content'].map(model.infer_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vec = data['doc_vec']\n",
    "hours_played = data['hours_all']\n",
    "comp = data['compensation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "hours_played_scaled = minmax_scale(hours_played, feature_range= (0,1), axis = 0, copy = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-df9d5c045510>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdoc_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m46169\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhours_played_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhours_played_scaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m46169\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcomp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m46169\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# print(new_data.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "# new_data = np.vstack((doc_vec, hours_played_scaled, comp))\n",
    "# new_data = np.vstack((doc_vec, hours_played_scaled, comp])).reshape(46169,3)\n",
    "doc_vec = doc_vec.reshape(1, 46169)\n",
    "hours_played_scaled = hours_played_scaled.reshape(1, 46169)\n",
    "comp = comp.values.reshape(1,46169)\n",
    "\n",
    "# print(new_data.shape)\n",
    "# print(new_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.as_matrix of 0        [0.005809192, 0.0013914531, -0.011887878, -0.0...\n",
      "1        [-0.040256817, 0.004481264, 0.044122715, -0.05...\n",
      "2        [0.012847292, -0.0012835631, -0.004706556, -0....\n",
      "3        [0.0026366932, 0.014811996, -0.009830314, -0.0...\n",
      "4        [-0.034745686, -0.038029794, -0.027089985, -0....\n",
      "5        [0.010525068, 0.004605245, -0.007871234, 0.000...\n",
      "6        [0.0057089925, 0.015486509, -0.011018858, 0.00...\n",
      "7        [-0.00048519342, 0.0014340155, -0.0027292995, ...\n",
      "8        [0.01546066, -0.00066498364, -0.021535309, -0....\n",
      "9        [0.06429689, -0.07966819, -0.047984246, -0.073...\n",
      "10       [-0.018333472, 0.0010086348, 0.014274573, 0.00...\n",
      "11       [-0.0046486226, 0.014563507, -0.003147583, -0....\n",
      "12       [-0.004585385, -0.0011561584, -0.016749717, -0...\n",
      "13       [0.0065817055, 0.040071476, 0.02215917, 0.0311...\n",
      "14       [-0.02656216, -0.0049655843, 0.03597522, 0.006...\n",
      "15       [0.009882016, -0.0020508866, -0.010101916, -0....\n",
      "16       [0.015375565, -0.013337461, 0.003912641, 0.007...\n",
      "17       [-0.026874091, 0.001207477, 0.004565643, -0.02...\n",
      "18       [0.010412632, -0.0151218595, -0.0059797396, -0...\n",
      "19       [-0.018541653, 0.0232578, 0.014545735, 0.00231...\n",
      "20       [0.10181362, 0.0771931, -0.02505471, -0.017987...\n",
      "21       [-0.012962319, 0.009950501, 0.00015926822, 0.0...\n",
      "22       [0.020435035, 0.031478506, 0.017313834, 0.0075...\n",
      "23       [0.018323207, 0.017872868, -0.014706651, 0.015...\n",
      "24       [0.0068493807, 0.010011235, 0.0011170454, -0.0...\n",
      "25       [0.041460894, 0.027318086, -0.0395571, 0.02254...\n",
      "26       [0.04139018, 0.012904441, -0.04361676, 0.02805...\n",
      "27       [-0.0140619585, 0.000599812, 0.00579781, 0.002...\n",
      "28       [-0.0019568445, -0.0005283572, 0.0014460499, -...\n",
      "29       [-0.00798937, -0.007119762, 0.0023292543, -0.0...\n",
      "                               ...                        \n",
      "46139                                                    0\n",
      "46140                                                    0\n",
      "46141                                                    0\n",
      "46142                                                    0\n",
      "46143                                                    0\n",
      "46144                                                    0\n",
      "46145                                                    0\n",
      "46146                                                    0\n",
      "46147                                                    0\n",
      "46148                                                    0\n",
      "46149                                                    0\n",
      "46150                                                    0\n",
      "46151                                                    0\n",
      "46152                                                    0\n",
      "46153                                                    0\n",
      "46154                                                    0\n",
      "46155                                                    0\n",
      "46156                                                    1\n",
      "46157                                                    0\n",
      "46158                                                    0\n",
      "46159                                                    0\n",
      "46160                                                    0\n",
      "46161                                                    0\n",
      "46162                                                    0\n",
      "46163                                                    0\n",
      "46164                                                    0\n",
      "46165                                                    0\n",
      "46166                                                    0\n",
      "46167                                                    0\n",
      "46168                                                    1\n",
      "Length: 138507, dtype: object>\n"
     ]
    }
   ],
   "source": [
    "new_data = pd.concat([pd.Series(doc_vec), pd.Series(hours_played_scaled), pd.Series(comp)])\n",
    "# new_data = new_data.reshape(46169, 3)\n",
    "new_data_mat = new_data.as_matrix\n",
    "print(new_data_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X, y):\n",
    "    # Get class weights and early stopping obj\n",
    "    class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                np.unique(y_train),\n",
    "                                                y_train)\n",
    "    \n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "    print(class_weight_dict)\n",
    "    \n",
    "    callbacks = [EarlyStopping(monitor = 'val_loss', patience = 10),\n",
    "            ModelCheckpoint(filepath = 'cv_model_checkpoint.h5', monitor = 'val_loss', save_best_only = True)]\n",
    "    \n",
    "    print(\"Training model...\")\n",
    "    result = model.fit(X, \n",
    "              y, \n",
    "              batch_size = 128,\n",
    "              epochs = 25, \n",
    "              validation_data = (X_val_pad, y_val), \n",
    "              verbose = 2, \n",
    "              callbacks = callbacks, \n",
    "              class_weight = class_weight_dict, \n",
    "              shuffle = True)\n",
    "    \n",
    "    return result;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model(128, 302)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
